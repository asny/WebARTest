<!--
/*
 * Copyright 2017 Google Inc. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<!DOCTYPE html>
<html lang="en">
<head>
  <title>three.ar.js - Surfaces</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, user-scalable=no,
  minimum-scale=1.0, maximum-scale=1.0">
  <style>
    body {
      font-family: monospace;
      margin: 0;
      overflow: hidden;
      position: fixed;
      width: 100%;
      height: 100vh;
      -webkit-user-select: none;
      user-select: none;
    }
    #info {
      position: absolute;
      left: 50%;
      bottom: 0;
      transform: translate(-50%, 0);
      margin: 1em;
      z-index: 10;
      display: block;
      width: 100%;
      line-height: 2em;
      text-align: center;
    }
    #info * {
      color: #fff;
    }
    .title {
      background-color: rgba(40, 40, 40, 0.4);
      padding: 0.4em 0.6em;
      border-radius: 0.1em;
    }
    .links {
      background-color: rgba(40, 40, 40, 0.6);
      padding: 0.4em 0.6em;
      border-radius: 0.1em;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
  </style>
</head>
<body>
<div id="info">
  <span class="title">Render detected surfaces.</span><br/>
  <span class="links">
    <a href="https://github.com/google-ar/three.ar.js">three.ar.js</a> -
    <a href="https://developers.google.com/ar/develop/web/getting-started#examples">examples</a>
  </span>
</div>
<script src="./three.js"></script>
<script src="./VRControls.js"></script>
<script src="./three.ar.js"></script>
<script>

var vrDisplay, vrControls, vrFrameData, arView;
var canvas, camera, scene, renderer;
var products = [];

/**
 * Use the `getARDisplay()` utility to leverage the WebVR API
 * to see if there are any AR-capable WebVR VRDisplays. Returns
 * a valid display if found. Otherwise, display the unsupported
 * browser message.
 */
THREE.ARUtils.getARDisplay().then(function (display) {
  if (display) {
    vrFrameData = new VRFrameData();
    vrDisplay = display;
    init();
  } else {
    THREE.ARUtils.displayUnsupportedMessage();
  }
});

function init() {
  // Setup the three.js rendering environment
  renderer = new THREE.WebGLRenderer({ alpha: true });
  renderer.setPixelRatio(window.devicePixelRatio);
  renderer.setSize(window.innerWidth, window.innerHeight);
  renderer.autoClear = false;
  canvas = renderer.domElement;
  document.body.appendChild(canvas);
  scene = new THREE.Scene();

  // Turn on the debugging panel
  var arDebug = new THREE.ARDebug(vrDisplay, scene, {
    showLastHit: true,
    showPoseStatus: true,
    showPlanes: true,
  });
  document.body.appendChild(arDebug.getElement());

  // Creating the ARView, which is the object that handles
  // the rendering of the camera stream behind the three.js
  // scene
  arView = new THREE.ARView(vrDisplay, renderer);

  // The ARPerspectiveCamera is very similar to THREE.PerspectiveCamera,
  // except when using an AR-capable browser, the camera uses
  // the projection matrix provided from the device, so that the
  // perspective camera's depth planes and field of view matches
  // the physical camera on the device.
  camera = new THREE.ARPerspectiveCamera(
    vrDisplay,
    60,
    window.innerWidth / window.innerHeight,
    vrDisplay.depthNear,
    vrDisplay.depthFar
  );

  // VRControls is a utility from three.js that applies the device's
  // orientation/position to the perspective camera, keeping our
  // real world and virtual world in sync.
  vrControls = new THREE.VRControls(camera);

  // Bind our event handlers
  window.addEventListener('resize', onWindowResize, false);

  // Create Scene
  scene.add( new THREE.DirectionalLight( 0xffffff, 0.5 ) );

  createProduct(new THREE.Vector3(-0.3, 0.5, -1.0), 'T-shirt');
  createProduct(new THREE.Vector3(-0.3, 0.0, -1.0), 'Jeans');
  createProduct(new THREE.Vector3(0.3, 0.0, -1.0), 'Shoes');
  createProduct(new THREE.Vector3(0.3, 0.5, -1.0), 'Dress');

  // Kick off the render loop!
  update();
}

function createProduct(position, text)
{
  var geometry = new THREE.TorusKnotGeometry( 0.05, 0.02, 100, 16 );
  //var geometry = new THREE.SphereGeometry( 0.05, 32, 32 );
  var material = new THREE.MeshStandardMaterial();
	material.roughness = 0.5;
	material.metalness = 0.5;
  var mesh = new THREE.Mesh( geometry, material );
  mesh.translateX(position.x);
  mesh.translateY(position.y);
  mesh.translateZ(position.z);
  scene.add( mesh );

  // Text
  // load a texture, set wrap mode to repeat
  //var texture = new THREE.TextureLoader().load( "test.png" );
  //texture.wrapS = THREE.RepeatWrapping;
  //texture.wrapT = THREE.RepeatWrapping;
  //texture.repeat.set( 1, 1 );
  //create image
  var bitmap = document.createElement('canvas');
  var g = bitmap.getContext('2d');
  bitmap.width = 100;
  bitmap.height = 100;
  g.font = 'Bold 20px Arial';

  g.fillStyle = 'black';
  g.fillText(text, 0, 20);
  g.strokeStyle = 'black';
  g.strokeText(text, 0, 20);

  // canvas contents will be used for a texture
  var texture = new THREE.Texture(bitmap)
  texture.needsUpdate = true;
  texture.magFilter = THREE.NearestFilter;
  texture.minFilter = THREE.NearestFilter;

  var geometry = new THREE.PlaneGeometry( 0.5, 0.5, 32, 32 );
  var material = new THREE.MeshBasicMaterial( {map : texture, side: THREE.DoubleSide} );
  var textGeometry = new THREE.Mesh( geometry, material );
  textGeometry.translateX(position.x);
  textGeometry.translateY(position.y);
  textGeometry.translateZ(position.z);
  scene.add( textGeometry );
  var product = {anchor:mesh, description:textGeometry};
  products.push(product);
}

/**
 * The render loop, called once per frame. Handles updating
 * our scene and rendering.
 */
function update() {
  // Clears color from the frame before rendering the camera (arView) or scene.
  renderer.clearColor();

  // Render the device's camera stream on screen first of all.
  // It allows to get the right pose synchronized with the right frame.
  arView.render();

  // Update our camera projection matrix in the event that
  // the near or far planes have updated
  camera.updateProjectionMatrix();

  // From the WebVR API, populate `vrFrameData` with
  // updated information for the frame
  vrDisplay.getFrameData(vrFrameData);

  // Update our perspective camera's positioning
  vrControls.update();

  // Fetch the pose data from the current frame
  var pose = vrFrameData.pose;

  var pos = new THREE.Vector3(
    pose.position[0],
    pose.position[1],
    pose.position[2]
  );

  for(var i = 0; i < products.length; i++)
  {
    var product = products[i];
    if(pos.distanceTo(product.anchor.position) < 1.0)
    {
      product.anchor.visible = false;
      product.description.visible = true;
    }
    else {
      product.anchor.visible = true;
      product.description.visible = false;
    }

    product.anchor.rotation.x += 0.01;
  	product.anchor.rotation.y += 0.01;
  }

  // Render our three.js virtual scene
  renderer.clearDepth();
  renderer.render(scene, camera);

  // Kick off the requestAnimationFrame to call this function
  // when a new VRDisplay frame is rendered
  vrDisplay.requestAnimationFrame(update);
}

/**
 * On window resize, update the perspective camera's aspect ratio,
 * and call `updateProjectionMatrix` so that we can get the latest
 * projection matrix provided from the device
 */
function onWindowResize () {
  camera.aspect = window.innerWidth / window.innerHeight;
  camera.updateProjectionMatrix();
  renderer.setSize(window.innerWidth, window.innerHeight);
}
</script>
</body>
</html>
