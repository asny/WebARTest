<!--
/*
 * Copyright 2017 Google Inc. All Rights Reserved.
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<!DOCTYPE html>
<html lang="en">
<head>
  <title>Beaware</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, user-scalable=no,
  minimum-scale=1.0, maximum-scale=1.0">
  <style>
    body {
      font-family: monospace;
      margin: 0;
      overflow: hidden;
      position: fixed;
      width: 100%;
      height: 100vh;
      -webkit-user-select: none;
      user-select: none;
    }
    #info {
      position: absolute;
      left: 50%;
      bottom: 0;
      transform: translate(-50%, 0);
      margin: 1em;
      z-index: 10;
      display: block;
      width: 100%;
      line-height: 2em;
      text-align: center;
    }
    #info * {
      color: #fff;
    }
    .title {
      background-color: rgba(40, 40, 40, 0.4);
      padding: 0.4em 0.6em;
      border-radius: 0.1em;
    }
    .links {
      background-color: rgba(40, 40, 40, 0.6);
      padding: 0.4em 0.6em;
      border-radius: 0.1em;
    }
    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
  </style>
</head>
<body>
  <canvas id="canvas"></canvas>
  <div style="display:none;">
    <img id="source" src="assets/logo1.png"
         width="800" height="800">
  </div>

	<video id="video" autoplay loop webkit-playsinline style="display:none">
		<source src="assets/sintel.mp4" type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'>
		<source src="assets/sintel.ogv" type='video/ogg; codecs="theora, vorbis"'>
	</video>
	<!--<video id="video" autoplay loop webkit-playsinline style="display:none">
		<source src="assets/t_shirt.mp4" type='video/mp4; codecs="avc1.42E01E, mp4a.40.2"'>
	</video>-->
<!--<div id="info">
  <span class="title">Render detected surfaces.</span><br/>
  <span class="links">
    <a href="https://github.com/google-ar/three.ar.js">three.ar.js</a> -
    <a href="https://developers.google.com/ar/develop/web/getting-started#examples">examples</a>
  </span>
</div>-->
<script src="./three.js"></script>
<script src="./VRControls.js"></script>
<script src="./three.ar.js"></script>
<script src="./numeric.js"></script>
<script src="./OBJLoader.js"></script>
<script src="./assets/product-info.js"></script>
<script>

var vrDisplay, vrControls, vrFrameData, arView;
var canvas, camera, scene, renderer;
var products = [];
var recordedHits = [];
var videoTexture, videoContext, video, videoImage;
var anchorModel;

/**
 * Use the `getARDisplay()` utility to leverage the WebVR API
 * to see if there are any AR-capable WebVR VRDisplays. Returns
 * a valid display if found. Otherwise, display the unsupported
 * browser message.
 */
THREE.ARUtils.getARDisplay().then(function (display) {
  if (display) {
    vrFrameData = new VRFrameData();
    vrDisplay = display;
    init();
  } else {
    THREE.ARUtils.displayUnsupportedMessage();
  }
});

function init() {
  // Setup the three.js rendering environment
  renderer = new THREE.WebGLRenderer({ alpha: true });
  renderer.setPixelRatio(window.devicePixelRatio);
  renderer.setSize(window.innerWidth, window.innerHeight);
  renderer.autoClear = false;
  canvas = renderer.domElement;
  document.body.appendChild(canvas);
  scene = new THREE.Scene();

  // Turn on the debugging panel
  var arDebug = new THREE.ARDebug(vrDisplay, scene, {
    showLastHit: true,
    showPoseStatus: true,
    showPlanes: true,
  });
  document.body.appendChild(arDebug.getElement());

  // Creating the ARView, which is the object that handles
  // the rendering of the camera stream behind the three.js
  // scene
  arView = new THREE.ARView(vrDisplay, renderer);

  // The ARPerspectiveCamera is very similar to THREE.PerspectiveCamera,
  // except when using an AR-capable browser, the camera uses
  // the projection matrix provided from the device, so that the
  // perspective camera's depth planes and field of view matches
  // the physical camera on the device.
  camera = new THREE.ARPerspectiveCamera(
    vrDisplay,
    60,
    window.innerWidth / window.innerHeight,
    vrDisplay.depthNear,
    vrDisplay.depthFar
  );

  // VRControls is a utility from three.js that applies the device's
  // orientation/position to the perspective camera, keeping our
  // real world and virtual world in sync.
  vrControls = new THREE.VRControls(camera);

  // Bind our event handlers
  window.addEventListener('resize', onWindowResize, false);
  canvas.addEventListener('touchstart', onClick, false);

  // Add lights
  scene.add( new THREE.DirectionalLight( 0xffffff, 0.5 ) );
  scene.add(new THREE.AmbientLight( 0x555555 ));

  // model
	var manager = new THREE.LoadingManager();
	manager.onProgress = function ( item, loaded, total ) {

		console.log( item, loaded, total );

	};
  var onProgress = function ( xhr ) {
    if ( xhr.lengthComputable ) {
      var percentComplete = xhr.loaded / xhr.total * 100;
      console.log( Math.round(percentComplete, 2) + '% downloaded' );
    }
  };

  var onError = function ( xhr ) {
  };

  var loader = new THREE.OBJLoader( manager );
  loader.load( 'assets/logo.obj', function ( object ) {

    anchorModel = object;

  }, onProgress, onError );

  // Kick off the render loop!
  update();
}

/**
 * When clicking on the screen, fire a ray from where the user clicked
 * on the screen and if a hit is found, place a cube there.
 */
function onClick (e)
{
  // If we don't have a touches object, abort
  // TODO: is this necessary?
  if (isInitialized() || !e.touches[0]) {
    return;
  }

  // Inspect the event object and generate normalize screen coordinates
  // (between 0 and 1) for the screen position.
  var x = e.touches[0].pageX / window.innerWidth;
  var y = e.touches[0].pageY / window.innerHeight;

  // Send a ray from the point of click to the real world surface
  // and attempt to find a hit. `hitTest` returns an array of potential
  // hits.
  var hits = vrDisplay.hitTest(x, y);

  // If a hit is found, just use the first one
  if (hits && hits.length) {
    // Record hit
    var hit = hits[0];
    var modelMatrix = new THREE.Matrix4();
    modelMatrix.fromArray(hit.modelMatrix);
    var pos = new THREE.Vector3();
    pos.setFromMatrixPosition( modelMatrix );
    recordedHits.push(pos);

    // Add hit geometry
    var geometry = new THREE.SphereGeometry( 0.05, 32, 32 );
    var material = new THREE.MeshStandardMaterial();
    var hitMesh = new THREE.Mesh( geometry, material );
    scene.add(hitMesh);
    hitMesh.position.set(pos.x, pos.y, pos.z);

    if(isInitialized())
    {
      createProducts();
    }
  }
}

function createProducts()
{
  var x1 = new THREE.Vector3(0, -0.5, 0.5);
  var x2 = new THREE.Vector3(-0.3, -0.5, 0);
  var x3 = new THREE.Vector3(0.3, -0.5, 0);

  var localToWorld = estimateTransformation([x1, x2, x3], recordedHits);

  createProduct(new THREE.Vector3(-0.3, 0.1, 0.0), localToWorld, productInfos[0]);
  createProduct(new THREE.Vector3(0.3, 0.2, 0.0), localToWorld, productInfos[1]);
  createProduct(new THREE.Vector3(-0.3, 0.4, 0.0), localToWorld, productInfos[2]);
  createProduct(new THREE.Vector3(0.3, 0.6, 0.0), localToWorld, productInfos[3]);
  createProduct(new THREE.Vector3(-0.3, 0.7, 0.0), localToWorld, productInfos[4]);
  createProduct(new THREE.Vector3(0.3, 0.9, 0.0), localToWorld, productInfos[5]);

  // Video
  video = document.getElementById( 'video' );

  videoImage = document.createElement( 'canvas' );
  videoImage.width = 480;
  videoImage.height = 204;

  videoContext = videoImage.getContext( '2d' );
  videoContext.fillStyle = '#000000';
  videoContext.fillRect( 0, 0, 480, 204 );

  videoTexture = new THREE.Texture( videoImage );
  var material = new THREE.MeshBasicMaterial( { map: videoTexture, overdraw: 0.5 } );

	var plane = new THREE.PlaneGeometry( 0.5, 0.5, 32, 32 );

  var trans = new THREE.Vector3();
  var rot = new THREE.Quaternion();
  var scale = new THREE.Vector3();
  localToWorld.decompose(trans, rot, scale);

	var mesh = new THREE.Mesh( plane, material );
  mesh.position.copy(trans);
  mesh.quaternion.copy(rot);
	scene.add(mesh);
}

function estimateTransformation(X, Y)
{
  // Estimate translation
  var nSamples = X.length;
  var xAvg = new THREE.Vector3();
  var yAvg = new THREE.Vector3();
  for(var i = 0; i < nSamples; i++)
  {
    xAvg.add(X[i]);
    yAvg.add(Y[i]);
  }
  xAvg.multiplyScalar(1.0 / nSamples);
  yAvg.multiplyScalar(1.0 / nSamples);

  var translation = yAvg.clone().sub(xAvg);

  // Estimate rotation
  var P = new Array(nSamples);
  var Q = new Array(nSamples);
  for (var i = 0; i < nSamples; i++) {
    P[i] = [X[i].x - xAvg.x, X[i].y - xAvg.y, X[i].z - xAvg.z];
    Q[i] = [Y[i].x - yAvg.x, Y[i].y - yAvg.y, Y[i].z - yAvg.z];
  }

  var A = numeric.dot(numeric.transpose(P), Q);
  var svd = numeric.svd(A);
  var V = svd.U;
  var WT = numeric.transpose(svd.V);
  var det = numeric.det(numeric.dot(V, WT));
  var D = [[1.0, 0.0, 0.0],[0.0, 1.0, 0.0],[0.0, 0.0, det]];
  var R = numeric.dot(V, numeric.dot(D, WT));

  // Create matrix
  var localToWorld = new THREE.Matrix4();
  localToWorld.set(R[0][0], R[1][0], R[2][0], translation.x,
                  R[0][1], R[1][1], R[2][1], translation.y,
                  R[0][2], R[1][2], R[2][2], translation.z,
                  0.0, 0.0, 0.0, 1.0);

  return localToWorld;
}

function createProduct(position, localToWorld, productInfo)
{
  var trans = new THREE.Vector3();
  var rot = new THREE.Quaternion();
  var scale = new THREE.Vector3();
  localToWorld.decompose(trans, rot, scale);

  var xAxis = new THREE.Vector3(), yAxis = new THREE.Vector3(), zAxis = new THREE.Vector3();
  localToWorld.extractBasis(xAxis, yAxis, zAxis);

  var p = trans.clone().add(xAxis.clone().multiplyScalar(position.x).add(yAxis.clone().multiplyScalar(position.y)).add(zAxis.clone().multiplyScalar(position.z)));

  // ANCHOR
  // Create anchor
  var mesh = anchorModel.clone();
  mesh.material = new THREE.MeshStandardMaterial();
	mesh.material.roughness = 0.5;
	mesh.material.metalness = 0.5;
  mesh.position.copy(p);
  mesh.quaternion.copy(rot);
  mesh.rotation.x -= 0.5 * Math.PI;
  mesh.scale.set(0.0001, 0.0001, 0.0001);
  scene.add( mesh );

  // TEXT
  // Create image
  var bitmap = document.createElement('canvas');
  var context = bitmap.getContext('2d');
  bitmap.width = 700;
  bitmap.height = 700;

  // Create background
  var image = document.getElementById('source');
  context.drawImage(image, 0, 0, bitmap.width, bitmap.height);

  // Draw product title
  var lineHeight = 60;
  var marginX = lineHeight * 2;
  var marginY = lineHeight * 3;
  context.font = '56px Open Sans';
  context.fillStyle = 'black';
  marginY = wrapText(context, productInfo.ProductTitle, marginX, marginY, bitmap.width - 2 * marginX, lineHeight);

  // Draw teaser
  lineHeight = 40;
  marginY += lineHeight;
  context.font = '28px Open Sans';
  context.fillStyle = 'black';
  marginY = wrapText(context, productInfo.Teaser, marginX, marginY, bitmap.width - 2 * marginX, lineHeight);

  // Draw certifications
  marginX += lineHeight * 0.25;
  for(var i = 0; i < productInfo.Certification.length; i++)
  {
    marginY = wrapText(context, " - " + productInfo.Certification[i], marginX, marginY, bitmap.width - 2 * marginX, lineHeight);
  }

  // Draw environmental effects
  marginY += lineHeight;
  context.font = '18px bold Open Sans';
  lineHeight = 20;
  for(var i = 0; i < productInfo.EnvironmentalEffects.effect.length; i++)
  {
    var effect = productInfo.EnvironmentalEffects.effect[i];
    marginY = wrapText(context, effect["@name"] + ": " + effect["#text"], marginX, marginY, bitmap.width - 2 * marginX, lineHeight);
  }

  // Create a texture
  var texture = new THREE.Texture(bitmap);
  texture.needsUpdate = true;
  texture.magFilter = THREE.NearestFilter;
  texture.minFilter = THREE.NearestFilter;

  // Create text geometry
  var geometry = new THREE.PlaneGeometry( 0.25, 0.25, 8, 8 );
  var material = new THREE.MeshBasicMaterial( {map : texture, side: THREE.DoubleSide, transparent: true, opacity: 0.8} );
  var textGeometry = new THREE.Mesh( geometry, material );
  var p2 = p.clone().addScaledVector(zAxis, 0.04);
  textGeometry.position.copy(p2);
  textGeometry.quaternion.copy(rot);
  scene.add( textGeometry );

  // Save product information
  var product = {anchor:mesh, description:textGeometry, animation:0.0};
  products.push(product);
}

function isInitialized()
{
  return recordedHits.length == 3;
}

var lastTime = new Date().getTime();
/**
 * The render loop, called once per frame. Handles updating
 * our scene and rendering.
 */
function update() {
  // Clears color from the frame before rendering the camera (arView) or scene.
  renderer.clearColor();

  // Render the device's camera stream on screen first of all.
  // It allows to get the right pose synchronized with the right frame.
  arView.render();

  // Update our camera projection matrix in the event that
  // the near or far planes have updated
  camera.updateProjectionMatrix();

  // From the WebVR API, populate `vrFrameData` with
  // updated information for the frame
  vrDisplay.getFrameData(vrFrameData);

  // Update our perspective camera's positioning
  vrControls.update();

  if(isInitialized())
  {
    // Fetch the pose data from the current frame
    var pose = vrFrameData.pose;

    var pos = new THREE.Vector3(
      pose.position[0],
      pose.position[1],
      pose.position[2]
    );
    updateProducts(pos);

    console.log("Damn " + video.readyState + ": " + video.HAVE_ENOUGH_DATA);
    // Update video
    if ( video.readyState == video.HAVE_ENOUGH_DATA ) {

      videoContext.drawImage( video, 0, 0 );
      console.log("HAHa");

      if ( videoTexture ) videoTexture.needsUpdate = true;

    }
  }

  // Render our three.js virtual scene
  renderer.clearDepth();
  renderer.render(scene, camera);

  // Kick off the requestAnimationFrame to call this function
  // when a new VRDisplay frame is rendered
  vrDisplay.requestAnimationFrame(update);
}

function updateProducts(pos)
{
    var currentTime = (new Date().getTime() - lastTime) / 1000;
    var closestProduct = -1;
    var closestDist = 1000000.0;
    for(var i = 0; i < products.length; i++)
    {
      var dist = pos.distanceTo(products[i].anchor.position);
      if(dist < 1.0 && closestDist > dist)
      {
        closestDist = dist;
        closestProduct = i;
      }
    }

    for(var i = 0; i < products.length; i++)
    {
      var product = products[i];
      var animation = product.animation + 0.001 * currentTime * ( closestProduct == i ? 1.0 : - 1.0 );
      product.animation = Math.min(1.0, Math.max(0.0, animation));
      product.description.scale.set(product.animation, product.animation, product.animation);

      product.description.visible = product.animation > 0.00001;

      //product.anchor.rotation.x += 0.015;
    	//product.anchor.rotation.y += 0.01;
    	product.anchor.rotation.z += 0.01;
    }
}

/**
 * On window resize, update the perspective camera's aspect ratio,
 * and call `updateProjectionMatrix` so that we can get the latest
 * projection matrix provided from the device
 */
function onWindowResize () {
  camera.aspect = window.innerWidth / window.innerHeight;
  camera.updateProjectionMatrix();
  renderer.setSize(window.innerWidth, window.innerHeight);
}

function wrapText(context, text, x, y, maxWidth, lineHeight)
{
  var cars = text.split("\n");

  for (var ii = 0; ii < cars.length; ii++) {

      var line = "";
      var words = cars[ii].split(" ");

      for (var n = 0; n < words.length; n++) {
          var testLine = line + words[n] + " ";
          var metrics = context.measureText(testLine);
          var testWidth = metrics.width;

          if (testWidth > maxWidth) {
              context.fillText(line, x, y);
              line = words[n] + " ";
              y += lineHeight;
          }
          else {
              line = testLine;
          }
      }

      context.fillText(line, x, y);
      y += lineHeight;
  }
  return y;
}
</script>
</body>
</html>
